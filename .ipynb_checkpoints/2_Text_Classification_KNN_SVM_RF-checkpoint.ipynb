{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "\n",
    "1. Introduction and Importing Libraries\n",
    "2. Data Preprocessing and Feature Engineering\n",
    "3. Model Building- Machine Learning\n",
    "    a. Naive Bayes\n",
    "    b. Random Forest\n",
    "    c. XGBoost\n",
    "\n",
    "4. Hyperparameter Tuning\n",
    "5. Conclusion and Saving the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# import Label Encoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "      <th>Article_Length</th>\n",
       "      <th>Summary_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "      <td>timewarner said fourth quarter sales rose to b...</td>\n",
       "      <td>business</td>\n",
       "      <td>403</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar gains on greenspan speechthe dollar has...</td>\n",
       "      <td>the dollar has hit its highest level against t...</td>\n",
       "      <td>business</td>\n",
       "      <td>377</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yukos unit buyer faces loan claimthe owners of...</td>\n",
       "      <td>yukos owner menatep group says it will ask ros...</td>\n",
       "      <td>business</td>\n",
       "      <td>261</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high fuel prices hit bas profitsbritish airway...</td>\n",
       "      <td>rod eddington bas chief executive said the res...</td>\n",
       "      <td>business</td>\n",
       "      <td>376</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pernod takeover talk lifts domecqshares in uk ...</td>\n",
       "      <td>pernod has reduced the debt it took on to fund...</td>\n",
       "      <td>business</td>\n",
       "      <td>254</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  ad sales boost time warner profitquarterly pro...   \n",
       "1  dollar gains on greenspan speechthe dollar has...   \n",
       "2  yukos unit buyer faces loan claimthe owners of...   \n",
       "3  high fuel prices hit bas profitsbritish airway...   \n",
       "4  pernod takeover talk lifts domecqshares in uk ...   \n",
       "\n",
       "                                             Summary  Category  \\\n",
       "0  timewarner said fourth quarter sales rose to b...  business   \n",
       "1  the dollar has hit its highest level against t...  business   \n",
       "2  yukos owner menatep group says it will ask ros...  business   \n",
       "3  rod eddington bas chief executive said the res...  business   \n",
       "4  pernod has reduced the debt it took on to fund...  business   \n",
       "\n",
       "   Article_Length  Summary_Length  \n",
       "0             403             125  \n",
       "1             377             159  \n",
       "2             261             121  \n",
       "3             376             186  \n",
       "4             254             100  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Resources/Clean_Data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Article           0\n",
       "Summary           0\n",
       "Category          0\n",
       "Article_Length    0\n",
       "Summary_Length    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Drop NULL values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "    # Remove punctuation\n",
    "    filtered_sentence = [w for w in filtered_sentence if w.isalpha()]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in filtered_sentence]\n",
    "\n",
    "    return \" \".join(lemmatized)\n",
    "\n",
    "\n",
    "df['clean_text'] = df['Article'].apply(clean_text)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[['clean_text', 'Category']]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Transform the text into TF-IDF vectors\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# Create a dataframe from the TF-IDF vectors\n",
    "X = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "\n",
    "# Create the target vector\n",
    "y = df['Category']\n",
    "\n",
    "\n",
    "# Split the dataframe into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print('Training set shape:', X_train.shape, y_train.shape)\n",
    "print('Test set shape:', X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Value counts of Y train\n",
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Value count in Y-test\n",
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get Label names\n",
    "\n",
    "labels = df['Category'].unique()\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Encode the labels\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder\n",
    "\n",
    "le.fit(y_train)\n",
    "le.fit(y_test)\n",
    "\n",
    "# Transform the labels\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building- Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the model\n",
    "\n",
    "nv_model = MultinomialNB()\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "nv_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nv_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Print value in boxes in format\n",
    "sns.heatmap(cm, annot=True, xticklabels=labels,\n",
    "            yticklabels=labels, cmap='Blues')\n",
    "\n",
    "# Labels\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Title\n",
    "\n",
    "plt.title('Confusion Matrix for Naive Bayes Model')\n",
    "\n",
    "# Save the plot\n",
    "\n",
    "plt.savefig('Resources/Images/CM_NB.png',\n",
    "            dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Print value in boxes in format\n",
    "sns.heatmap(cm, annot=True, xticklabels=labels,\n",
    "            yticklabels=labels, cmap='Blues')\n",
    "\n",
    "# Labels\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Title\n",
    "\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "\n",
    "# Save the plot\n",
    "\n",
    "plt.savefig('Resources/Images/CM_RF.png',\n",
    "            dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. X-Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the fast xgboost model\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Print value in boxes in format\n",
    "sns.heatmap(cm, annot=True, xticklabels=labels,\n",
    "            yticklabels=labels, cmap='Blues')\n",
    "\n",
    "# Labels\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Title\n",
    "\n",
    "plt.title('Confusion Matrix for XGBoosting Model')\n",
    "\n",
    "# Save the plot\n",
    "\n",
    "plt.savefig('Resources/Images/CM_XG.png',\n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameter grid for grid search naives bayes\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "# Create the model\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Create the grid search object\n",
    "\n",
    "grid_search = GridSearchCV(estimator=nb_model, param_grid=param_grid,\n",
    "                            cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the best parameters\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "\n",
    "# Get the best estimator\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Print value in boxes in format\n",
    "sns.heatmap(cm, annot=True, xticklabels=labels,\n",
    "            yticklabels=labels, cmap='Blues')\n",
    "\n",
    "# Labels\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Title\n",
    "\n",
    "plt.title('Confusion Matrix for Naive Bayes ( Hyper Parameter Tuning)')\n",
    "\n",
    "# Save the plot\n",
    "\n",
    "plt.savefig('Resources/Images/CM_GS_NB.png',\n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open('Resources/Models/Random_Forest_Model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "\n",
    "\n",
    "# Save the model\n",
    "with open('Resources/Images/NB_Model.pkl', 'wb') as f:\n",
    "    pickle.dump(nv_model, f)\n",
    "\n",
    "\n",
    "# Save the model\n",
    "with open('Resources/Models/XGBoost_Model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "\n",
    "\n",
    "# Save the grid search object\n",
    "\n",
    "with open('Resources/Models/Grid_Search_NaiveBayes.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search, f)\n",
    "\n",
    "\n",
    "# Save the vectorizer\n",
    "with open('Resources/Extras/TFIDF_Vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "\n",
    "# Save the encoder\n",
    "with open('Resources/Extras/Label_Encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "\n",
    "# Save the labels\n",
    "with open('Resources/Extras/Labels.pkl', 'wb') as f:\n",
    "    pickle.dump(labels, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
